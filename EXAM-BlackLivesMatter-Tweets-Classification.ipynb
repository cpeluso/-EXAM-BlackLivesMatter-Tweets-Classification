{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Preprocessing\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import treetaggerwrapper as ttpw\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# from num2words import num2words\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from sklearn.utils import resample\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "The dataset chosen for this text classification project contains tweets related to the Black Lives Matter movement, which was founded in 2013 and gained international attention in May 2020 in USA.\n",
    "\n",
    "The dataset is composed of 80000 labelled tweets and for each tweet there are also some informations about the user that published it and the tweet itself.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "* ”1” if the tweet shows a positive sentiment towards the movement.\n",
    "* ”0” if the tweet shows a negative sentiment towards the movement.\n",
    "\n",
    "The distribution of the tweets between the two classes is balanced: there are 40069 tweets classified as 0 and 39931 tweets classified as 1.\n",
    "\n",
    "Also the average length of tweets between the two classes is similar: class 0 tweets have an average length of 121 characters, while class 1 tweets have an average length of 133 characters.\n",
    "\n",
    "Analysing the dataset, it pops also out that there are a lot of retweets and most of the tweets are duplicates, so, inspecting more the dataset, we can see that there are 35006 distinct tweets.\n",
    "\n",
    "The quality of the tweets is also quite low: there are often unicode characters, emojis and web-links, most of them are trimmed and they are also hardly classifiable even for a human:\n",
    "\n",
    "`yes if u mean this one https://t.co/r9MaeWmRy7`<br/>\n",
    "`@magicalhyunjin USE TOO`<br/>\n",
    "`RT @NotReallyaDr: Happy birthday, Chris!`<br/>\n",
    "\n",
    "The informations about the tweets mentioned before are a subset of the attributes of the Tweet object [1].\n",
    "\n",
    "The correlation between the labels and the informations about tweets and users resulted very low. <br/>\n",
    "Furthermore, the quality of the informations is low: there are a lot of missing values, often incorrigible by applying some interpolations.\n",
    "\n",
    "For these reasons, I decided to drop every information and develop a model only with the tweets and them labels.\n",
    "\n",
    "Due to the previously explained problems about the tweets, in the following steps (especially in the Preprocessing one) we will see that a non-invasive text cleaning approach pays more for this text classification task, since in some tweets there are so few features that even the user mentioned (’@’) could be useful to classify a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing \n",
    "\n",
    "The full preprocessing pipeline scheduled for this project is the following: \n",
    "\n",
    "* Cut unicode characters and make text lowercase\n",
    "* Cut mentions (’@’)\n",
    "* Apply a Tagger [2] on the text or apply a Stemmer [3], [4]\n",
    "* Cut websites’ links\n",
    "* Convert emojis [5] to text\n",
    "* Remove punctuation\n",
    "* Remove stopwords\n",
    "* Remove ”RT” word\n",
    "\n",
    "Although, this pipeline was too invasive and so I decided to maintain the essential steps, in particular those that don’t remove the words used:\n",
    "\n",
    "* Cut unicode characters and make text lowercase \n",
    "* Apply a Tagger [2] on the text\n",
    "* Cut websites’ links\n",
    "* Convert emojis [5] to text\n",
    "\n",
    "Unicode characters were mainly present at the end of the tweets as suspension points. Since they do not provide any information to the classifier, I decided to cut them off.\n",
    "\n",
    "Removing the user mentioned and the ”RT” word led to a clean text. However, as anticipated in the Data Exploration step, the features extractable for certain tweets are few and even the user mentioned could be used as a feature. This is also true for stopwords, that when removed could lead to almost empty tweets. <br/>\n",
    "Of course this approach should not be followed when using a bigger dataset, because the need of the usernames (or indiscriminate features, in general) to classify a tweet is certainly synonym of overfitting.\n",
    "\n",
    "I also involved a lemmatization process in order to reduce each word to its base form and to flat out different words to represent the same feature.<br/>\n",
    "To do so I used the TreeTagger tool [2]. Its effects are the following:\n",
    "\n",
    "`This is a very short text`\n",
    "`this be a very short text`\n",
    "\n",
    "Finally, emojis to text conversion was helpful for two main reasons:\n",
    "\n",
    "1. A certain sequence of emojis are used for the users to express appreciation for the Black Lives Matter movement\n",
    "2. Instead of being discarded, emojis have become a feature.\n",
    "\n",
    "After this preprocessing pipeline, I used TfidfVectorizer [6] from sklearn in order to transform the reviews into a TF-IDF features matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40069 tweets classified as 0.\n",
      "There are 39931 tweets classified as 1.\n",
      "\n",
      "Distinct tweets inside train dataset: 35006\n",
      "\n",
      "The average length of tweets labelled as 0 is 121.8228056602361\n",
      "The average length of tweets labelled as 1 is 133.4803285667777\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bawdzisnaughty sgfgjay radioshadilay you be a ...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt bigipipi : ive be stay largely offline beca...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rt emanisblazed : this website have a huge lis...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rt elijahdaniel : why be it 8am and i be liter...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rt youranoncentral : report from the battle : ...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                          full_text  text_length\n",
       "0      0  bawdzisnaughty sgfgjay radioshadilay you be a ...           93\n",
       "1      1  rt bigipipi : ive be stay largely offline beca...          139\n",
       "2      1  rt emanisblazed : this website have a huge lis...          140\n",
       "3      0  rt elijahdaniel : why be it 8am and i be liter...          123\n",
       "4      0  rt youranoncentral : report from the battle : ...          124"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_data = load_dataset(\"development.jsonl\")\n",
    "test_data = load_dataset(\"evaluation.jsonl\")\n",
    "\n",
    "# Explore data\n",
    "explore_data(train_data)\n",
    "\n",
    "# Preprocessing\n",
    "train_data[\"full_text\"] = train_data[\"full_text\"].apply(lambda tweet: preprocess(tweet))\n",
    "test_data[\"full_text\"] = test_data[\"full_text\"].apply(lambda tweet: preprocess(tweet))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithm choice\n",
    "\n",
    "Initially, I make an inspection using 5 different classifiers: \n",
    "\n",
    "* SGD Classifier [7]\n",
    "* Random Forest Classifier [8] \n",
    "* Logistic Regressor [9]\n",
    "* SVC [10]\n",
    "* LinearSVC [11]\n",
    "\n",
    "The evaluation set was made up of the 20% of the development set.\n",
    "\n",
    "![title](Accuracies.png)\n",
    "\n",
    "Before doing hyperparameters tuning, the SGDClassifier reached 89,31% of accuracy. After this first attempt, I compared it to the other classifiers and decided to not tune it because it wasn’t promising.\n",
    "\n",
    "After the SGDClassifier, I tried the RandomForestClassifier, which performed well on evaluation set and led to an accuracy of 91.475%. So, I decided to do some hyperparameters tuning on it (more on next section), but the accuracy did not increase so much: it gained just 0.05% of accuracy (91.525%).\n",
    "\n",
    "In addition, I tried to use the LogisticRegressor; I thought that this regressor could be a good one for this project because of its capability on modelling binary classification problems. Using the LogisticRegressor the accuracy reached 92%. <br/>\n",
    "Once tuned, this model was the only in which I can highlight a significant increase, since the accuracy raised up to 93.275%.\n",
    "\n",
    "Finally, I decided to try the SVC and the LinearSVC classifiers, assuming that even with the small preprocessing steps done before the dataset was splitted as clearly as possible into two different clusters.<br/>\n",
    "Initially, the SVC classifier and the LinearSVC achieved an accuracy of 92.7% and 93.24%, respectively.<br/>\n",
    "Since training the SVC is quite time consuming, the accuracy found was lower than its linear version and so the dataset seemed to be linearly separable, I chose to only tune the latter.<br/>\n",
    "By the way, the improvements achieved by means of the hyperparameters tuning on LinearSVC were inexistent on evaluation set, and the final accuracy remained the same.\n",
    "\n",
    "Even if Support Vector Machine algorithm (with linear kernel) perform similarly to the Logistic Regression, I think that the first one performs better on this project because of the sensitivity to marginal values. The sigmoid function of the LogisticRegressor tends to not properly identify simil-neutral values, while the Support Vector Machine algorithm tries to construct the best widest possible separating line to split this two clusters.\n",
    "\n",
    "All the evaluation for the accuracy were done with accuracy score, as suggested in the assignment, and all the classifiers were provided by the Scikit Learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier\n",
      "\n",
      "Accuracy: \n",
      "(accuracy_score):0.89675\n",
      "(f1_score): 0.8960246376811595\n",
      "- - -\n",
      "\n",
      "Random Forest Classifier\n",
      "\n",
      "Accuracy: \n",
      "(accuracy_score):0.91275\n",
      "(f1_score): 0.9125036332058113\n",
      "- - -\n",
      "\n",
      "Logistic Regressor\n",
      "\n",
      "Accuracy: \n",
      "(accuracy_score):0.92075\n",
      "(f1_score): 0.920639457234545\n",
      "- - -\n",
      "\n",
      "Linear SVC\n",
      "\n",
      "Accuracy: \n",
      "(accuracy_score):0.9314375\n",
      "(f1_score): 0.9314208595510693\n",
      "- - -\n",
      "\n",
      "SVC\n",
      "Accuracy: \n",
      "(accuracy_score):0.927125\n",
      "(f1_score): 0.9270016380730695\n",
      "- - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer, X_train, X_test, y_train, y_test = split_dataset(train_data)\n",
    "X_train_scaled, X_test_scaled = scale_dataset(X_train, X_test)\n",
    "classifiers = [\"SGD\", \"RFC\", \"LR\", \"LSVC\", \"SVC\"] # \"SGD\", \"RFC\", \"LR\", \"LSVC\", \"SVC\"\n",
    "\n",
    "# SGD Classifier\n",
    "\n",
    "if \"SGD\" in classifiers:\n",
    "    print(\"SGD Classifier\\n\")\n",
    "    classifier = SGDClassifier(n_jobs=4, max_iter=300000, random_state=42) # , loss=\"hinge\", penalty=\"l2\"\n",
    "    _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "if \"RFC\" in classifiers:\n",
    "    print(\"Random Forest Classifier\\n\")\n",
    "    classifier = RandomForestClassifier(n_jobs=4, random_state=42) # n_estimators=100, \n",
    "    _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# Logistic Regressor\n",
    "\n",
    "if \"LR\" in classifiers:\n",
    "    print(\"Logistic Regressor\\n\")\n",
    "    classifier = LogisticRegression(n_jobs=4, max_iter=300000, random_state=42) # tol=0.01, \n",
    "    _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# LinearSVC\n",
    "\n",
    "if \"LSVC\" in classifiers:\n",
    "    print(\"Linear SVC\\n\")\n",
    "    classifier = svm.LinearSVC(max_iter=300000, random_state=42)\n",
    "    _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# SVM\n",
    "\n",
    "if \"SVC\" in classifiers:\n",
    "    print(\"SVC\")\n",
    "    classifier = svm.SVC(max_iter = 300000, random_state=42) #tol=0.1, \n",
    "    _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"- - -\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tuning and validation\n",
    "\n",
    "* Random Forest Classifier: <br/>\n",
    "    num estimators in [20, 50, 80, 100, 120]\n",
    "* Logistic Regressor: <br/>\n",
    "    C in range(1,101)\n",
    "* LinearSVC:<br/>\n",
    "    C in [0.1, 0.5, 0.7, 1, 10, 20, 30, 40],<br/>\n",
    "    tol in [0.1, 0.01, 0.001, 0.0001, 0.00005, 0.00001, 0.000005]\n",
    "    \n",
    "For the TfidfVectorizer, I fixed ngram range to (1, 2), especially because I didn’t dropped any word from the tweets.\n",
    "\n",
    "![title](Accuracies-2.png)\n",
    "\n",
    "\n",
    "In order to tune properly the classifiers I tried different values of one main parameter, C (for Logistic Regressor and LinearSVC) and the number of estimators for the Random Forest Classifier.\n",
    "\n",
    "The reason why in the previous step I mentioned that the Random Forest Classifier when tuned didn’t increased the accuracy is that the best number of estimators found was 100, which is also the default value for this classifier.\n",
    "\n",
    "For the other classifiers, LinearSVC and Logistic Regressor, I thought that C was the most important parameter I should have worked on, since I developed a small preprocessing pipeline and marginal values could have been a problem.\n",
    "\n",
    "After some attempts, for the LinearSVC classifier I ended up that C = 0.7 was the best in terms of accuracy. So, this classifier works better with a large margin around the hyperplane. Moreover, the best tollerance value found is 0.01. The accuracy reached on evaluation set is 93.24%, while in test set the accuracy is 93.39%.\n",
    "\n",
    "The best C value found for the Logistic Regressor is 35. This means that this model is more prone to overfit the data, and the confirmation comes also from the leaderboard: in fact, the accuracy on evaluation set is 93.27% and on test set is also 93.27%.\n",
    "\n",
    "So, comparing the Logistic Regressor with the LinearSVC and their best C values, we can see that the Logistic Regressor performs better on the evaluation set because it overfits the data (C = 35), but then on test set the LinearSVC achieves better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier\n",
      "\n",
      "Best number of estimators: 100\n",
      "Max accuracy: 0.91525\n",
      "- - -\n",
      "\n",
      "Logistic Regressor\n",
      "\n",
      "Best C: 35\n",
      "Max accuracy: 0.93275\n",
      "- - -\n",
      "\n",
      "Linear SVC\n",
      "\n",
      "Best C and tol: 1,0.1\n",
      "Max accuracy: 0.9324375\n",
      "- - -\n"
     ]
    }
   ],
   "source": [
    "vectorizer, X_train, X_test, y_train, y_test = split_dataset(train_data)\n",
    "X_train_scaled, X_test_scaled = scale_dataset(X_train, X_test)\n",
    "classifiers = [\"RFC\", \"LR\", \"LSVC\"] # \"RFC\", \"LR\", \"LSVC\"\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "if \"RFC\" in classifiers:\n",
    "\n",
    "    print(\"Random Forest Classifier\\n\")\n",
    "\n",
    "    accuracies = {}\n",
    "\n",
    "    for num_estimators in [20, 50, 80, 100, 120]:\n",
    "        classifier = RandomForestClassifier(n_jobs=4, n_estimators=num_estimators)\n",
    "        _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test, print_accuracy=False)\n",
    "        accuracies[str(num_estimators)] = float(accuracy)\n",
    "\n",
    "    #relevant_features(vectorizer, classifier)\n",
    "    best_num_estimators, max_accuracy = get_best_parameter(accuracies, \"Best number of estimators:\")\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# Logistic Regressor\n",
    "\n",
    "if \"LR\" in classifiers:\n",
    "\n",
    "    print(\"Logistic Regressor\\n\")\n",
    "\n",
    "    accuracies = {}\n",
    "\n",
    "    for c in range(1,101):\n",
    "        classifier = LogisticRegression(C=c, n_jobs=4, max_iter=300000)\n",
    "        _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test, print_accuracy=False)\n",
    "        accuracies[str(c)] = float(accuracy)\n",
    "\n",
    "    #relevant_features(vectorizer, classifier)\n",
    "    best_c, max_accuracy = get_best_parameter(accuracies, \"Best C:\")\n",
    "\n",
    "    print(\"- - -\\n\")\n",
    "\n",
    "# Linear SVC\n",
    "\n",
    "if \"LSVC\" in classifiers:\n",
    "    \n",
    "    joint_tuning = True\n",
    "    tune_c = False\n",
    "    tune_tol = False\n",
    "\n",
    "    print(\"Linear SVC\\n\")\n",
    "\n",
    "    accuracies = {}\n",
    "    \n",
    "    if joint_tuning == True:\n",
    "        for c in [0.1, 0.5, 0.7, 1, 10, 20, 30, 40]:\n",
    "            for tol in [0.1, 0.01, 0.001, 0.0001, 0.00005, 0.00001, 0.000005]:        \n",
    "                classifier = svm.LinearSVC(C=c, tol=tol, max_iter=300000)\n",
    "                _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test, print_accuracy=False)\n",
    "                accuracies[str(c) + \",\" + str(tol)] = float(accuracy)\n",
    "\n",
    "        #relevant_features(vectorizer, classifier)\n",
    "        best_c, max_accuracy = get_best_parameter(accuracies, \"Best C and tol:\")\n",
    "    \n",
    "    accuracies = {}\n",
    "    if tune_c == True:\n",
    "        for c in [0.1, 0.5, 0.7, 1, 10, 20, 30, 40]:\n",
    "            classifier = svm.LinearSVC(C=c, max_iter=300000)\n",
    "            _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test, print_accuracy=False)\n",
    "            accuracies[str(c)] = float(accuracy)\n",
    "\n",
    "        #relevant_features(vectorizer, classifier)\n",
    "        best_c, max_accuracy = get_best_parameter(accuracies, \"Best C:\")\n",
    "\n",
    "    accuracies = {}\n",
    "    if tune_tol == True:\n",
    "        for tol in [0.1, 0.01, 0.001, 0.0001, 0.00005, 0.00001, 0.000005]:\n",
    "            classifier = svm.LinearSVC(tol=tol, max_iter=300000)\n",
    "            _, accuracy, predictions = train(classifier, X_train, X_test, y_train, y_test, print_accuracy=False)\n",
    "            accuracies[str(tol)] = float(accuracy)\n",
    "\n",
    "        #relevant_features(vectorizer, classifier)\n",
    "        best_c, max_accuracy = get_best_parameter(accuracies, \"Best tol:\")\n",
    "\n",
    "    print(\"- - -\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! :)\n"
     ]
    }
   ],
   "source": [
    "classifier0 = svm.LinearSVC(C=0.7, tol = 0.01, max_iter=300000) # 0.9314375 on local, 0.9339 on leaderboard\n",
    "\n",
    "classifier1 = svm.LinearSVC(C=1, tol = 0.1, max_iter=300000) # 0.9324375 on local, 0.9335 on leaderboard \n",
    "\n",
    "predictions = predict(classifier0, train_data, test_data)\n",
    "export(predictions, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    data = pd.read_json(filename, lines=True)\n",
    "    \n",
    "    data.drop(['id',\\\n",
    "               'id_str',\\\n",
    "               'metadata',\\\n",
    "               'source',\\\n",
    "               'lang',\\\n",
    "               'coordinates',\\\n",
    "               'place',\\\n",
    "               'created_at',\\\n",
    "               'in_reply_to_status_id_str',\\\n",
    "               'in_reply_to_status_id',\\\n",
    "               'in_reply_to_user_id_str',\\\n",
    "               'in_reply_to_user_id',\\\n",
    "               'quoted_status_id_str',\\\n",
    "               'quoted_status_id',\\\n",
    "               'quoted_status',\\\n",
    "               'in_reply_to_screen_name',\\\n",
    "               'withheld_in_countries',\\\n",
    "               'display_text_range',\\\n",
    "               'retweeted',\\\n",
    "               'favorited',\\\n",
    "               'truncated',\\\n",
    "               'contributors',\\\n",
    "               'user',\\\n",
    "               'is_quote_status',\\\n",
    "               'retweet_count',\\\n",
    "               'favorite_count',\\\n",
    "               'possibly_sensitive'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def explore_data(train_data, plot = False):\n",
    "    print(\"There are \" + str(train_data[\"class\"].value_counts()[0]) + \" tweets classified as 0.\")\n",
    "    print(\"There are \" + str(train_data[\"class\"].value_counts()[1]) + \" tweets classified as 1.\")\n",
    "    print()\n",
    "    print(\"Distinct tweets inside train dataset:\", str(len(train_data[train_data['full_text'].duplicated() == False][\"full_text\"])))\n",
    "\n",
    "    train_data['text_length'] = [len(t) for t in train_data.full_text]\n",
    "    \n",
    "    mean_length_class_0 = train_data[train_data[\"class\"] == 0].text_length.mean()\n",
    "    mean_length_class_1 = train_data[train_data[\"class\"] == 1].text_length.mean()\n",
    "    \n",
    "    print()\n",
    "    print(\"The average length of tweets labelled as 0 is \" + str(mean_length_class_0))\n",
    "    print(\"The average length of tweets labelled as 1 is \" + str(mean_length_class_1))\n",
    "    \n",
    "    if plot == True:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        plt.boxplot(train_data.text_length)\n",
    "        plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "punc_list = [\".\",\"_\",\";\",\":\",\"!\",\"?\",\"/\",\"\\\\\",\",\",\"$\",\"&\",\")\",\"(\",\"'\",\"\\\"\", \"#\"]\n",
    "stopwords = [stopword.replace(\"\\n\", \"\") for stopword in open(\"stopwords.txt\", \"r\")]\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "stemmer = PorterStemmer()\n",
    "tagger = ttpw.TreeTagger(TAGLANG='en', TAGDIR =\"/Users/carlopeluso/Downloads\")\n",
    "\n",
    "def preprocess(text):\n",
    "    # Exclude non-ascii characters\n",
    "    text = ''.join([word for word in text for i in range(len(word)) if ord(word[i]) <= 127])\n",
    "    \n",
    "    # Make text lowercase\n",
    "    text = text.lower().replace(\"@\", \"\")\n",
    "    \n",
    "    # Tagger\n",
    "    tags = tagger.tag_text(text)\n",
    "    text = ' '.join([t.split('\\t')[-1] for t in tags])\n",
    "    \n",
    "    # Cut mentions\n",
    "    #text = ' '.join([word for word in text.split(\" \") if not word.startswith(\"@\")])\n",
    "    \n",
    "    # Cut websites' links\n",
    "    #text = re.sub('https?://[A-Za-z0-9./]+','',text)\n",
    "    \n",
    "    # Transform emojis into text\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Remove punctuations defined inside punctuation list\n",
    "    #t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    #text = text.translate(t)\n",
    "    \n",
    "    # Stemmer\n",
    "    #text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    # Cut of \"rt\" and \"twitter\"\n",
    "    #text = \" \".join([word for word in text.lower().split() if word not in [\"rt\", \"twitter\"]])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def full_preprocess(text):\n",
    "    \n",
    "    text = ''.join([word for word in text for i in range(len(word)) if ord(word[i]) <= 127])\n",
    "    \n",
    "    # Make text lowercase\n",
    "    text = text.lower().replace(\"@\", \"\")\n",
    "    \n",
    "    # Cut mentions\n",
    "    text = ' '.join([word for word in text.split(\" \") if not word.startswith(\"@\")])\n",
    "    \n",
    "    # Tagger\n",
    "    tags = tagger.tag_text(text)\n",
    "    text = ' '.join([t.split('\\t')[-1] for t in tags])\n",
    "    \n",
    "    # Cut websites' links\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+','',text)\n",
    "    \n",
    "    # Transform emojis into text\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Remove punctuations defined inside punctuation list\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.translate(t)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    \n",
    "    # Stemmer\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    # Cut of \"rt\" and \"twitter\"\n",
    "    text = \" \".join([word for word in text.lower().split() if word not in [\"rt\", \"twitter\"]])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# - - - \n",
    "\n",
    "def split_dataset(data):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(data[\"full_text\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, data.loc[:, \"class\"], test_size=0.2, random_state=0)\n",
    "    \n",
    "    return vectorizer, X_train, X_test, y_train, y_test\n",
    "    \n",
    "def train(classifier, X_train, X_test, y_train, y_test, print_accuracy = True, *args):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    if print_accuracy == True:\n",
    "        print(\"Accuracy: \\n(accuracy_score):%s\" % (accuracy_score(y_test, predictions)))\n",
    "        print(\"(f1_score):\", f1_score(y_test, predictions, average='weighted'))\n",
    "    \n",
    "    return classifier, accuracy, predictions\n",
    "\n",
    "def grid_search(classifier, train_data, *args):\n",
    "    vectorizer, X_train, X_test, y_train, y_test = split_dataset(train_data)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Max accuracy: \", classifier.best_score_)\n",
    "    print(\"Best model: \", classifier.best_estimator_)\n",
    "    \n",
    "def relevant_features(vectorizer, classifier, *args):\n",
    "    feature_to_coef = {\n",
    "        word: coef for word, coef in zip(\n",
    "            vectorizer.get_feature_names(), classifier.coef_[0]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print(\"\\nBest words for BLM\")\n",
    "    for best_positive in sorted(\n",
    "            feature_to_coef.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True)[:5]:\n",
    "        print(best_positive)\n",
    "    \n",
    "    print(\"\\nBest words against BLM\")\n",
    "    for best_negative in sorted(\n",
    "            feature_to_coef.items(),\n",
    "            key=lambda x: x[1])[:5]:\n",
    "        print(best_negative)\n",
    "\n",
    "def get_best_parameter(accuracies, title, plot=False):\n",
    "    \n",
    "    if plot == True:\n",
    "        accuracies_df = pd.DataFrame.from_dict(accuracies, orient='index',columns=[\"accuracy\"])\n",
    "        sns.lineplot(x=accuracies_df.index, y = \"accuracy\", data= accuracies_df)\n",
    "    \n",
    "    best_param = max(accuracies, key=accuracies.get)\n",
    "    max_accuracy = accuracies[str(best_param)]\n",
    "\n",
    "    print(title, best_param)\n",
    "    print(\"Max accuracy:\", max_accuracy)\n",
    "    \n",
    "    return best_param, max_accuracy\n",
    "        \n",
    "def predict(classifier, train_data, test_data, scaled = None, *args):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    X_train = vectorizer.fit_transform(train_data[\"full_text\"])\n",
    "    X_test = vectorizer.transform(test_data[\"full_text\"])\n",
    "\n",
    "    if scaled is not None:\n",
    "        scaler = MaxAbsScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, train_data.loc[:, \"class\"])\n",
    "\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def export(predictions, test_data):\n",
    "    \n",
    "    with open('exam_export.csv', 'w') as file:\n",
    "        file.write(\"Id,Predicted\\n\")\n",
    "        for index in test_data.index:\n",
    "            s = predictions[index]\n",
    "            file.write(str(index) + \",\" + str(s) + \"\\n\")\n",
    "    print(\"Done! :)\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
